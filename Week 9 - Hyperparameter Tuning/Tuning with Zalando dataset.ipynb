{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_name(idx):\n",
    "    if (idx == 0):\n",
    "        return '(0) T-shirt/top'\n",
    "    elif (idx == 1):\n",
    "        return '(1) Trouser'\n",
    "    elif (idx == 2):\n",
    "        return '(2) Pullover'\n",
    "    elif (idx == 3):\n",
    "        return '(3) Dress'\n",
    "    elif (idx == 4):\n",
    "        return '(4) Coat'\n",
    "    elif (idx == 5):\n",
    "        return '(5) Sandal'\n",
    "    elif (idx == 6):\n",
    "        return '(6) Shirt'\n",
    "    elif (idx == 7):\n",
    "        return '(7) Sneaker'\n",
    "    elif (idx == 8):\n",
    "        return '(8) Bag'\n",
    "    elif (idx == 9):\n",
    "        return '(9) Ankle boot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('fashion-mnist_train.csv', header = 0)\n",
    "data_test = pd.read_csv('fashion-mnist_test.csv', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 785)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data_train['label'].values.reshape(1, 60000)\n",
    "\n",
    "labels_ = np.zeros((60000, 10))\n",
    "labels_[np.arange(60000), labels] = 1\n",
    "labels_ = labels_.transpose()\n",
    "\n",
    "\n",
    "train = data_train.drop('label', axis=1).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 60000)\n",
      "(784, 60000)\n"
     ]
    }
   ],
   "source": [
    "print(labels_.shape)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = data_test['label'].values.reshape(1, 10000)\n",
    "\n",
    "labels_test_ = np.zeros((10000, 10))\n",
    "labels_test_[np.arange(10000), labels_test] = 1\n",
    "labels_test_ = labels_test_.transpose()\n",
    "\n",
    "\n",
    "test = data_test.drop('label', axis=1).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(train / 255.0)\n",
    "test = np.array(test / 255.0)\n",
    "labels_ = np.array(labels_)\n",
    "labels_test_ = np.array(labels_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cc4d0a8ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 5\n",
    "plt.imshow(train[:,idx].reshape(28,28), cmap = matplotlib.cm.binary, interpolation = \"nearest\")\n",
    "plt.axis(\"on\")\n",
    "plt.title(get_label_name(labels[:,idx]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 layer with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_layers(number_neurons):\n",
    "    n_dim = 784\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    \n",
    "    \n",
    "    # Number of neurons in the layers\n",
    "    n1 = number_neurons # Number of neurons in layer 1\n",
    "    n2 = number_neurons # Number of neurons in layer 2 \n",
    "    n3 = number_neurons\n",
    "    n4 = 10\n",
    "    #n5 = 10 # Neurons for the softmax function\n",
    "\n",
    "    cost_history = np.empty(shape=[0], dtype = float)\n",
    "    learning_rate = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "    stddev_f = 0.1\n",
    "\n",
    "    tf.set_random_seed(5)\n",
    "\n",
    "    X = tf.placeholder(tf.float32, [n_dim, None])\n",
    "    Y = tf.placeholder(tf.float32, [10, None])\n",
    "    W1 = tf.Variable(tf.random_normal([n1, n_dim], stddev=stddev_f)) \n",
    "    b1 = tf.Variable(tf.constant(0.0, shape = [n1,1]) )\n",
    "    W2 = tf.Variable(tf.random_normal([n2, n1], stddev=stddev_f)) \n",
    "    b2 = tf.Variable(tf.constant(0.0, shape = [n2,1])) \n",
    "    W3 = tf.Variable(tf.random_normal([n3,n2], stddev = stddev_f))\n",
    "    b3 = tf.Variable(tf.constant(0.0, shape = [n3,1]))\n",
    "    W4 = tf.Variable(tf.random_normal([n4,n3], stddev = stddev_f))\n",
    "    b4 = tf.Variable(tf.constant(0.0, shape = [n4,1]))\n",
    "    #W5 = tf.Variable(tf.truncated_normal([n5,n4], stddev = stddev_f))\n",
    "    #b5 = tf.Variable(tf.constant(stddev_f, shape = [n5,1]))\n",
    "\n",
    "    # Let's build our network...\n",
    "    Z1 = tf.nn.relu(tf.matmul(W1, X) + b1) # n1 x n_dim * n_dim x n_obs = n1 x n_obs\n",
    "    Z2 = tf.nn.relu(tf.matmul(W2, Z1) + b2) # n2 x n1 * n1 * n_obs = n2 x n_obs\n",
    "    Z3 = tf.nn.relu(tf.matmul(W3, Z2) + b3)\n",
    "    Z4 = tf.matmul(W4, Z3) + b4\n",
    "    #Z4 = tf.nn.relu(tf.matmul(W4, Z3) + b4)\n",
    "    #Z5 = tf.matmul(W5,Z4) + b5\n",
    "    y_ = tf.nn.softmax(Z4,0) # n2 x n_obs (10 x None)\n",
    "\n",
    "\n",
    "    cost = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    return optimizer, cost, y_, X, Y, learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(number_neurons):\n",
    "    n_dim = 784\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    # Number of neurons in the layers\n",
    "    n1 = number_neurons# Number of neurons in layer 1\n",
    "    n2 = 10 # Number of neurons in output layer \n",
    "\n",
    "    cost_history = np.empty(shape=[1], dtype = float)\n",
    "    learning_rate = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "    X = tf.placeholder(tf.float32, [n_dim, None])\n",
    "    Y = tf.placeholder(tf.float32, [10, None])\n",
    "    W1 = tf.Variable(tf.truncated_normal([n1, n_dim], stddev=.1)) \n",
    "    b1 = tf.Variable(tf.constant(0.1, shape = [n1,1]) )\n",
    "    W2 = tf.Variable(tf.truncated_normal([n2, n1], stddev=.1)) \n",
    "    b2 = tf.Variable(tf.constant(0.1, shape = [n2,1])) \n",
    "\n",
    "    # Let's build our network...\n",
    "    Z1 = tf.nn.relu(tf.matmul(W1, X) + b1) # n1 x n_dim * n_dim x n_obs = n1 x n_obs\n",
    "    Z2 = tf.matmul(W2, Z1) + b2 # n2 x n1 * n1 * n_obs = n2 x n_obs\n",
    "    y_ = tf.nn.softmax(Z2,0) # n2 x n_obs (10 x None)\n",
    "\n",
    "    cost = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    return optimizer, cost, y_, X, Y, learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_layers(minibatch_size, training_epochs, features, classes, logging_step = 100, \n",
    "                 learning_r = 0.001, number_neurons = 15, debug = False):\n",
    "    \n",
    "    opt, c, y_, X, Y, learning_rate = build_model_layers(number_neurons)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    cost_history = []\n",
    "    for epoch in range(training_epochs+1):\n",
    "        for i in range(0, features.shape[1], minibatch_size):\n",
    "            X_train_mini = features[:,i:i + minibatch_size]\n",
    "            y_train_mini = classes[:,i:i + minibatch_size]\n",
    "\n",
    "            #if (i % 5000 == 0):\n",
    "            #    print('i = ',i)\n",
    "            \n",
    "            sess.run(opt, feed_dict = {X: X_train_mini, Y: y_train_mini, learning_rate: learning_r})\n",
    "        cost_ = sess.run(c, feed_dict={ X:features, Y: classes, learning_rate: learning_r})\n",
    "        cost_history = np.append(cost_history, cost_)\n",
    "\n",
    "        if ((epoch % logging_step == 0) & debug):\n",
    "                print(\"Reached epoch\",epoch,\"cost J =\", cost_)\n",
    "                \n",
    "    correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "    accuracy_train = accuracy.eval({X: train, Y: labels_, learning_rate: 0.001}, session = sess)\n",
    "    accuracy_test = accuracy.eval({X: test, Y: labels_test_, learning_rate: 0.001}, session = sess)\n",
    "                \n",
    "    return accuracy_train, accuracy_test, sess, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(minibatch_size, training_epochs, features, classes, logging_step = 100, learning_r = 0.001, number_neurons = 15):\n",
    "    \n",
    "    opt, c, y_, X, Y, learning_rate = build_model(number_neurons)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    cost_history = []\n",
    "    for epoch in range(training_epochs+1):\n",
    "        for i in range(0, features.shape[1], minibatch_size):\n",
    "            X_train_mini = features[:,i:i + minibatch_size]\n",
    "            y_train_mini = classes[:,i:i + minibatch_size]\n",
    "\n",
    "            #if (i % 5000 == 0):\n",
    "            #    print('i = ',i)\n",
    "            \n",
    "            sess.run(opt, feed_dict = {X: X_train_mini, Y: y_train_mini, learning_rate: learning_r})\n",
    "        cost_ = sess.run(c, feed_dict={ X:features, Y: classes, learning_rate: learning_r})\n",
    "        cost_history = np.append(cost_history, cost_)\n",
    "\n",
    "        if (epoch % logging_step == 0):\n",
    "                print(\"Reached epoch\",epoch,\"cost J =\", cost_)\n",
    "                \n",
    "    correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "    accuracy_train = accuracy.eval({X: train, Y: labels_, learning_rate: learning_r}, session = sess)\n",
    "    accuracy_test = accuracy.eval({X: test, Y: labels_test_, learning_rate: learning_r}, session = sess)\n",
    "                \n",
    "    return accuracy_train, accuracy_test, sess, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.327792\n",
      "Reached epoch 10 cost J = 0.283489\n",
      "Reached epoch 20 cost J = 0.223011\n",
      "Reached epoch 30 cost J = 0.185602\n",
      "Reached epoch 40 cost J = 0.163496\n",
      "Reached epoch 50 cost J = 0.149302\n",
      "Reached epoch 60 cost J = 0.139664\n",
      "Reached epoch 70 cost J = 0.132576\n",
      "Reached epoch 80 cost J = 0.126942\n",
      "Reached epoch 90 cost J = 0.122225\n",
      "Reached epoch 100 cost J = 0.118169\n",
      "0.75755\n",
      "0.754\n"
     ]
    }
   ],
   "source": [
    "%%time_it\n",
    "acc_train, acc_test, sess, cost_history = model(minibatch_size = 50, \n",
    "                              training_epochs = 100, \n",
    "                              features = train, \n",
    "                              classes = labels_, \n",
    "                              logging_step = 10,\n",
    "                              learning_r = 0.001,\n",
    "                              number_neurons = 15)\n",
    "\n",
    "print(acc_train)\n",
    "print(acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.325249\n",
      "Reached epoch 50 cost J = 0.292769\n",
      "Number: 1 Acc. Train: 0.201383 Acc. Test 0.2042\n",
      "Reached epoch 0 cost J = 0.323873\n",
      "Reached epoch 50 cost J = 0.165635\n",
      "Number: 5 Acc. Train: 0.639417 Acc. Test 0.6377\n",
      "Reached epoch 0 cost J = 0.325217\n",
      "Reached epoch 50 cost J = 0.162485\n",
      "Number: 10 Acc. Train: 0.639183 Acc. Test 0.6348\n",
      "Reached epoch 0 cost J = 0.326944\n",
      "Reached epoch 50 cost J = 0.145429\n",
      "Number: 15 Acc. Train: 0.687183 Acc. Test 0.6815\n",
      "Reached epoch 0 cost J = 0.322997\n",
      "Reached epoch 50 cost J = 0.141857\n",
      "Number: 25 Acc. Train: 0.690917 Acc. Test 0.6917\n",
      "Reached epoch 0 cost J = 0.323642\n",
      "Reached epoch 50 cost J = 0.139777\n",
      "Number: 30 Acc. Train: 0.6965 Acc. Test 0.6887\n",
      "Reached epoch 0 cost J = 0.314705\n",
      "Reached epoch 50 cost J = 0.126111\n",
      "Number: 50 Acc. Train: 0.73665 Acc. Test 0.7369\n"
     ]
    }
   ],
   "source": [
    "nn = [1,5,10,15,25,30, 50, 150]\n",
    "for nn_ in nn:\n",
    "    acc_train, acc_test, sess, cost_history = model(minibatch_size = 50, \n",
    "                              training_epochs = 50, \n",
    "                              features = train, \n",
    "                              classes = labels_, \n",
    "                              logging_step = 50,\n",
    "                              learning_r = 0.001,\n",
    "                              number_neurons = nn_)\n",
    "    print('Number:',nn_,'Acc. Train:', acc_train, 'Acc. Test', acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.305623\n",
      "Reached epoch 50 cost J = 0.109506\n",
      "Number: 150 Acc. Train: 0.78545 Acc. Test 0.7848\n"
     ]
    }
   ],
   "source": [
    "nn = [150]\n",
    "for nn_ in nn:\n",
    "    acc_train, acc_test, sess, cost_history = model(minibatch_size = 50, \n",
    "                              training_epochs = 50, \n",
    "                              features = train, \n",
    "                              classes = labels_, \n",
    "                              logging_step = 50,\n",
    "                              learning_r = 0.001,\n",
    "                              number_neurons = nn_)\n",
    "    print('Number:',nn_,'Acc. Train:', acc_train, 'Acc. Test', acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.274023\n",
      "Reached epoch 50 cost J = 0.0997691\n",
      "Number: 300 Acc. Train: 0.806267 Acc. Test 0.8067\n"
     ]
    }
   ],
   "source": [
    "nn = [300]\n",
    "for nn_ in nn:\n",
    "    acc_train, acc_test, sess, cost_history = model(minibatch_size = 50, \n",
    "                              training_epochs = 50, \n",
    "                              features = train, \n",
    "                              classes = labels_, \n",
    "                              logging_step = 50,\n",
    "                              learning_r = 0.001,\n",
    "                              number_neurons = nn_)\n",
    "    print('Number:',nn_,'Acc. Train:', acc_train, 'Acc. Test', acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.234059\n",
      "Reached epoch 50 cost J = 0.0857759\n",
      "Number: 1000 Acc. Train: 0.828117 Acc. Test 0.8316\n"
     ]
    }
   ],
   "source": [
    "nn = [1000]\n",
    "for nn_ in nn:\n",
    "    acc_train, acc_test, sess, cost_history = model(minibatch_size = 50, \n",
    "                              training_epochs = 50, \n",
    "                              features = train, \n",
    "                              classes = labels_, \n",
    "                              logging_step = 50,\n",
    "                              learning_r = 0.001,\n",
    "                              number_neurons = nn_)\n",
    "    print('Number:',nn_,'Acc. Train:', acc_train, 'Acc. Test', acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.195685\n",
      "Reached epoch 50 cost J = 0.0766994\n",
      "Number: 3000 Acc. Train: 0.8469 Acc. Test 0.8478\n",
      "Wall time: 35min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nn = [3000]\n",
    "for nn_ in nn:\n",
    "    acc_train, acc_test, sess, cost_history = model(minibatch_size = 50, \n",
    "                              training_epochs = 50, \n",
    "                              features = train, \n",
    "                              classes = labels_, \n",
    "                              logging_step = 50,\n",
    "                              learning_r = 0.001,\n",
    "                              number_neurons = nn_)\n",
    "    print('Number:',nn_,'Acc. Train:', acc_train, 'Acc. Test', acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cc192d29b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cc192d2c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rc('font', family='arial')\n",
    "plt.rc('xtick', labelsize='x-small')\n",
    "plt.rc('ytick', labelsize='x-small')\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "fig = plt.figure(figsize=(3.9, 3.1))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "\n",
    "ax.set_xlabel('Number of neurons in the hidden layer')\n",
    "ax.set_ylabel('Accuracy on the test dataset')\n",
    "plt.plot([1,5,10,15,25,30, 50, 150, 300, 1000, 3000], \n",
    "         [0.2042, 0.6377, 0.6348, 0.6815, 0.6917, 0.6887, 0.7369, 0.7848, 0.8067, 0.8316, 0.8416],\n",
    "        color = 'black')\n",
    "\n",
    "#plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.ylim(0,1)\n",
    "#plt.figure(figsize=(8,6))\n",
    "#plt.title(\"Cost Function vs. epoch number\")\n",
    "#plt.xlabel(\"epochs\")\n",
    "#plt.xlim((0,80))\n",
    "#plt.ylim((0,0.33))\n",
    "#plt.ylabel(\"Cost function $J$\")\n",
    "#plt.plot(range(len(cost_history)), cost_history)\n",
    "\n",
    "plt.xscale('log')\n",
    "fig.savefig('Figure_7-26'+'.png', format='png', dpi=300,bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.325125\n",
      "Reached epoch 50 cost J = 0.325125\n",
      "Number: 1 Acc. Train: 0.1 Acc. Test 0.1\n",
      "Reached epoch 0 cost J = 0.325155\n",
      "Reached epoch 50 cost J = 0.324985\n",
      "Number: 5 Acc. Train: 0.187 Acc. Test 0.19\n",
      "Reached epoch 0 cost J = 0.325125\n",
      "Reached epoch 50 cost J = 0.324584\n",
      "Number: 10 Acc. Train: 0.235317 Acc. Test 0.2403\n",
      "Reached epoch 0 cost J = 0.325325\n",
      "Reached epoch 50 cost J = 0.323418\n",
      "Number: 15 Acc. Train: 0.218983 Acc. Test 0.2157\n",
      "Reached epoch 0 cost J = 0.324865\n",
      "Reached epoch 50 cost J = 0.256246\n",
      "Number: 25 Acc. Train: 0.499867 Acc. Test 0.4958\n",
      "Reached epoch 0 cost J = 0.324831\n",
      "Reached epoch 50 cost J = 0.25852\n",
      "Number: 30 Acc. Train: 0.422367 Acc. Test 0.4173\n",
      "Reached epoch 0 cost J = 0.325196\n",
      "Reached epoch 50 cost J = 0.141386\n",
      "Number: 50 Acc. Train: 0.676683 Acc. Test 0.6797\n"
     ]
    }
   ],
   "source": [
    "nn = [1,5,10,15,25,30, 50]\n",
    "for nn_ in nn:\n",
    "    acc_train, acc_test, sess, cost_history = model_layers(minibatch_size = 50, \n",
    "                              training_epochs = 50, \n",
    "                              features = train, \n",
    "                              classes = labels_, \n",
    "                              logging_step = 50,\n",
    "                              learning_r = 0.001,\n",
    "                              number_neurons = nn_)\n",
    "    print('Number:',nn_,'Acc. Train:', acc_train, 'Acc. Test', acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_ = np.random.randint(low=35, high=60.0, size=(10))\n",
    "\n",
    "#r = - np.arange(0,1,0.05)*4.0\n",
    "r = -np.random.random([10])*4.0\n",
    "\n",
    "learning_ = 10**r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number: 52 learning 0.00121597393409 Acc. Train: 0.705 Acc. Test 0.7004\n",
      "Number: 39 learning 0.437125703907 Acc. Train: 0.1 Acc. Test 0.1\n",
      "Number: 49 learning 0.0591695853312 Acc. Train: 0.1 Acc. Test 0.1\n",
      "Number: 47 learning 0.00498280238205 Acc. Train: 0.825017 Acc. Test 0.8243\n",
      "Number: 53 learning 0.0104536544878 Acc. Train: 0.1 Acc. Test 0.1\n",
      "Number: 56 learning 0.0550769654956 Acc. Train: 0.1 Acc. Test 0.1\n",
      "Number: 52 learning 0.000357130373762 Acc. Train: 0.3123 Acc. Test 0.3088\n",
      "Number: 50 learning 0.138565210139 Acc. Train: 0.1 Acc. Test 0.1\n",
      "Number: 48 learning 0.139522070043 Acc. Train: 0.1 Acc. Test 0.1\n",
      "Number: 50 learning 0.214833496372 Acc. Train: 0.1 Acc. Test 0.1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(neurons_)):\n",
    "    #print('Number:',neurons_[i],'learning', learning_[i])\n",
    "    acc_train, acc_test, sess, cost_history = model_layers(minibatch_size = 50, \n",
    "                              training_epochs = 50, \n",
    "                              features = train, \n",
    "                              classes = labels_, \n",
    "                              logging_step = 50,\n",
    "                              learning_r = learning_[i],\n",
    "                              number_neurons = neurons_[i], debug = False)\n",
    "    print('Number:',neurons_[i],'learning', learning_[i], 'Acc. Train:', acc_train, 'Acc. Test', acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_ = np.random.randint(low=35, high=60.0, size=(5))\n",
    "\n",
    "#r = - np.arange(0,1,0.05)*4.0\n",
    "learning_ = np.random.random([5])*(0.01-0.001)+0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00609832,  0.00820416,  0.00692562,  0.00990794,  0.00249272])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number: 51 learning 0.00609831821206 Acc. Train: 0.835267 Acc. Test 0.8334\n",
      "Number: 51 learning 0.00820416458624 Acc. Train: 0.846017 Acc. Test 0.8417\n",
      "Number: 44 learning 0.00692561907161 Acc. Train: 0.83995 Acc. Test 0.8404\n",
      "Number: 43 learning 0.00990793571566 Acc. Train: 0.84755 Acc. Test 0.847\n",
      "Number: 58 learning 0.00249271519461 Acc. Train: 0.791 Acc. Test 0.7879\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(neurons_)):\n",
    "    #print('Number:',neurons_[i],'learning', learning_[i])\n",
    "    acc_train, acc_test, sess, cost_history = model_layers(minibatch_size = 50, \n",
    "                              training_epochs = 50, \n",
    "                              features = train, \n",
    "                              classes = labels_, \n",
    "                              logging_step = 50,\n",
    "                              learning_r = learning_[i],\n",
    "                              number_neurons = neurons_[i], debug = False)\n",
    "    print('Number:',neurons_[i],'learning', learning_[i], 'Acc. Train:', acc_train, 'Acc. Test', acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with mini-batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_ = np.random.randint(low=35, high=60.0, size=(5))\n",
    "\n",
    "#r = - np.arange(0,1,0.05)*4.0\n",
    "learning_ = np.random.random([5])*(0.01-0.001)+0.001\n",
    "\n",
    "mb_size_ = np.random.randint(low=20, high=80, size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([66, 40, 70, 71, 51])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb_size_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number: 36 learning 0.00774286333878 mb size 66 Acc. Train: 0.818267 Acc. Test 0.8151\n",
      "Number: 41 learning 0.0068067093709 mb size 40 Acc. Train: 0.83795 Acc. Test 0.8372\n",
      "Number: 51 learning 0.00756241635423 mb size 70 Acc. Train: 0.82745 Acc. Test 0.8277\n",
      "Number: 57 learning 0.00727651917086 mb size 71 Acc. Train: 0.8307 Acc. Test 0.8278\n",
      "Number: 48 learning 0.0010709564944 mb size 51 Acc. Train: 0.659183 Acc. Test 0.6604\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(neurons_)):\n",
    "    #print('Number:',neurons_[i],'learning', learning_[i])\n",
    "    acc_train, acc_test, sess, cost_history = model_layers(minibatch_size = mb_size_[i], \n",
    "                              training_epochs = 50, \n",
    "                              features = train, \n",
    "                              classes = labels_, \n",
    "                              logging_step = 50,\n",
    "                              learning_r = learning_[i],\n",
    "                              number_neurons = neurons_[i], debug = False)\n",
    "    print('Number:',neurons_[i],'learning', learning_[i], 'mb size',mb_size_[i],\n",
    "          'Acc. Train:', acc_train, 'Acc. Test', acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with mini-batch size complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_ = np.random.randint(low=35, high=60.0, size=(10))\n",
    "\n",
    "#r = - np.arange(0,1,0.05)*4.0\n",
    "r = -np.random.random([10])*3.0-1\n",
    "\n",
    "learning_ = 10**r\n",
    "\n",
    "mb_size_ = np.random.randint(low=20, high=80, size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00012797,  0.01948796,  0.00013022,  0.00028204,  0.00414294,\n",
       "        0.0419834 ,  0.01212683,  0.06793482,  0.09984361,  0.0845947 ])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number: 59 learning 0.000127972130513 mb size 57 Acc. Train: 0.142983 Acc. Test 0.1432\n",
      "Number: 41 learning 0.0194879551184 mb size 69 Acc. Train: 0.853167 Acc. Test 0.8535\n",
      "Number: 58 learning 0.000130223106061 mb size 65 Acc. Train: 0.16095 Acc. Test 0.1574\n",
      "Number: 58 learning 0.000282041605562 mb size 37 Acc. Train: 0.4727 Acc. Test 0.4735\n",
      "Number: 35 learning 0.00414294465431 mb size 27 Acc. Train: 0.83305 Acc. Test 0.8296\n",
      "Number: 43 learning 0.0419833979363 mb size 24 Acc. Train: 0.1 Acc. Test 0.1\n",
      "Number: 49 learning 0.0121268293662 mb size 46 Acc. Train: 0.858733 Acc. Test 0.8561\n",
      "Number: 36 learning 0.0679348165416 mb size 60 Acc. Train: 0.1 Acc. Test 0.1\n",
      "Number: 53 learning 0.0998436068389 mb size 63 Acc. Train: 0.1 Acc. Test 0.1\n",
      "Number: 58 learning 0.0845946984423 mb size 63 Acc. Train: 0.1 Acc. Test 0.1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(neurons_)):\n",
    "    #print('Number:',neurons_[i],'learning', learning_[i])\n",
    "    acc_train, acc_test, sess, cost_history = model_layers(minibatch_size = mb_size_[i], \n",
    "                              training_epochs = 50, \n",
    "                              features = train, \n",
    "                              classes = labels_, \n",
    "                              logging_step = 50,\n",
    "                              learning_r = learning_[i],\n",
    "                              number_neurons = neurons_[i], debug = False)\n",
    "    print('Number:',neurons_[i],'learning', learning_[i], 'mb size',mb_size_[i],\n",
    "          'Acc. Train:', acc_train, 'Acc. Test', acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_ = np.random.randint(low=35, high=60.0, size=(10))\n",
    "r = -np.random.random([10])*3.0-1\n",
    "learning_ = 10**r\n",
    "mb_size_ = np.random.randint(low=20, high=80, size = 10)\n",
    "epochs_ = np.random.randint(low = 40, high = 100, size = (10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 95 Number: 41 learning 0.00626467070005 mb size 48 Acc. Train: 0.850817 Acc. Test 0.8506\n",
      "epochs: 48 Number: 46 learning 0.00246417801667 mb size 43 Acc. Train: 0.798333 Acc. Test 0.8002\n",
      "epochs: 41 Number: 41 learning 0.0286441262134 mb size 61 Acc. Train: 0.862917 Acc. Test 0.8604\n",
      "epochs: 41 Number: 58 learning 0.000625828992856 mb size 65 Acc. Train: 0.477483 Acc. Test 0.4787\n",
      "epochs: 73 Number: 48 learning 0.0230103999933 mb size 50 Acc. Train: 0.1 Acc. Test 0.1\n",
      "epochs: 69 Number: 43 learning 0.0942246773651 mb size 74 Acc. Train: 0.1 Acc. Test 0.1\n",
      "epochs: 88 Number: 50 learning 0.0618388683733 mb size 75 Acc. Train: 0.1 Acc. Test 0.1\n",
      "epochs: 73 Number: 48 learning 0.000574365251649 mb size 70 Acc. Train: 0.546767 Acc. Test 0.5463\n",
      "epochs: 62 Number: 59 learning 0.000157271812968 mb size 24 Acc. Train: 0.48665 Acc. Test 0.4855\n",
      "epochs: 58 Number: 44 learning 0.0195280568964 mb size 61 Acc. Train: 0.1 Acc. Test 0.1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(neurons_)):\n",
    "    #print('Number:',neurons_[i],'learning', learning_[i])\n",
    "    acc_train, acc_test, sess, cost_history = model_layers(minibatch_size = mb_size_[i], \n",
    "                              training_epochs = epochs_[i], \n",
    "                              features = train, \n",
    "                              classes = labels_, \n",
    "                              logging_step = 50,\n",
    "                              learning_r = learning_[i],\n",
    "                              number_neurons = neurons_[i], debug = False)\n",
    "    print('epochs:', epochs_[i], 'Number:',neurons_[i],'learning', learning_[i], 'mb size',mb_size_[i],\n",
    "          'Acc. Train:', acc_train, 'Acc. Test', acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "acc_train, acc_test, sess, cost_history = model_layers(minibatch_size = mb_size_[2], \n",
    "                              training_epochs = epochs_[2], \n",
    "                              features = train, \n",
    "                              classes = labels_, \n",
    "                              logging_step = 50,\n",
    "                              learning_r = learning_[2],\n",
    "                              number_neurons = neurons_[2], debug = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_layers(number_neurons):\n",
    "    n_dim = 784\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    \n",
    "    \n",
    "    # Number of neurons in the layers\n",
    "    n1 = number_neurons # Number of neurons in layer 1\n",
    "    n2 = number_neurons # Number of neurons in layer 2 \n",
    "    n3 = number_neurons\n",
    "    n4 = 10\n",
    "    #n5 = 10 # Neurons for the softmax function\n",
    "\n",
    "    cost_history = np.empty(shape=[0], dtype = float)\n",
    "    learning_rate = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "    stddev_f = 0.1\n",
    "\n",
    "    tf.set_random_seed(5)\n",
    "\n",
    "    X = tf.placeholder(tf.float32, [n_dim, None])\n",
    "    Y = tf.placeholder(tf.float32, [10, None])\n",
    "    W1 = tf.Variable(tf.random_normal([n1, n_dim], stddev=stddev_f)) \n",
    "    b1 = tf.Variable(tf.constant(0.0, shape = [n1,1]) )\n",
    "    W2 = tf.Variable(tf.random_normal([n2, n1], stddev=stddev_f)) \n",
    "    b2 = tf.Variable(tf.constant(0.0, shape = [n2,1])) \n",
    "    W3 = tf.Variable(tf.random_normal([n3,n2], stddev = stddev_f))\n",
    "    b3 = tf.Variable(tf.constant(0.0, shape = [n3,1]))\n",
    "    W4 = tf.Variable(tf.random_normal([n4,n3], stddev = stddev_f))\n",
    "    b4 = tf.Variable(tf.constant(0.0, shape = [n4,1]))\n",
    "    #W5 = tf.Variable(tf.truncated_normal([n5,n4], stddev = stddev_f))\n",
    "    #b5 = tf.Variable(tf.constant(stddev_f, shape = [n5,1]))\n",
    "\n",
    "    # Let's build our network...\n",
    "    Z1 = tf.nn.relu(tf.matmul(W1, X) + b1) # n1 x n_dim * n_dim x n_obs = n1 x n_obs\n",
    "    Z2 = tf.nn.relu(tf.matmul(W2, Z1) + b2) # n2 x n1 * n1 * n_obs = n2 x n_obs\n",
    "    Z3 = tf.nn.relu(tf.matmul(W3, Z2) + b3)\n",
    "    Z4 = tf.matmul(W4, Z3) + b4\n",
    "    #Z4 = tf.nn.relu(tf.matmul(W4, Z3) + b4)\n",
    "    #Z5 = tf.matmul(W5,Z4) + b5\n",
    "    y_ = tf.nn.softmax(Z4,0) # n2 x n_obs (10 x None)\n",
    "\n",
    "\n",
    "    cost = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))\n",
    "    optimizer = optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate, \n",
    "                                                   beta1 = 0.9, beta2 = 0.999, epsilon = 1e-8).minimize(cost)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    return optimizer, cost, y_, X, Y, learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_layers(minibatch_size, training_epochs, features, classes, logging_step = 100, \n",
    "                 learning_r = 0.001, number_neurons = 15, debug = False):\n",
    "    \n",
    "    opt, c, y_, X, Y, learning_rate = build_model_layers(number_neurons)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    cost_history = []\n",
    "    for epoch in range(training_epochs+1):\n",
    "        for i in range(0, features.shape[1], minibatch_size):\n",
    "            X_train_mini = features[:,i:i + minibatch_size]\n",
    "            y_train_mini = classes[:,i:i + minibatch_size]\n",
    "\n",
    "            #if (i % 5000 == 0):\n",
    "            #    print('i = ',i)\n",
    "            \n",
    "            sess.run(opt, feed_dict = {X: X_train_mini, Y: y_train_mini, learning_rate: learning_r})\n",
    "        cost_ = sess.run(c, feed_dict={ X:features, Y: classes, learning_rate: learning_r})\n",
    "        cost_history = np.append(cost_history, cost_)\n",
    "\n",
    "        if ((epoch % logging_step == 0) & debug):\n",
    "                print(\"Reached epoch\",epoch,\"cost J =\", cost_)\n",
    "                \n",
    "    correct_predictions = tf.equal(tf.argmax(y_,0), tf.argmax(Y,0))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "    accuracy_train = accuracy.eval({X: train, Y: labels_, learning_rate: 0.001}, session = sess)\n",
    "    accuracy_test = accuracy.eval({X: test, Y: labels_test_, learning_rate: 0.001}, session = sess)\n",
    "                \n",
    "    return accuracy_train, accuracy_test, sess, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.26278\n",
      "Reached epoch 10 cost J = 0.0999409\n",
      "Reached epoch 20 cost J = 0.0861616\n",
      "Reached epoch 30 cost J = 0.0797902\n",
      "Reached epoch 40 cost J = 0.0756751\n",
      "0.84855\n",
      "0.847\n"
     ]
    }
   ],
   "source": [
    "acc_train, acc_test, sess, cost_history = model_layers(minibatch_size = 41, \n",
    "                              training_epochs = 41, \n",
    "                              features = train, \n",
    "                              classes = labels_, \n",
    "                              logging_step = 10,\n",
    "                              learning_r = 1e-5,\n",
    "                              number_neurons = 58, debug = True)\n",
    "print(acc_train)\n",
    "print(acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.31244\n",
      "Reached epoch 10 cost J = 0.188521\n",
      "Reached epoch 20 cost J = 0.135262\n",
      "Reached epoch 30 cost J = 0.117864\n",
      "Reached epoch 40 cost J = 0.108305\n",
      "Reached epoch 50 cost J = 0.101986\n",
      "Reached epoch 60 cost J = 0.0974232\n",
      "Reached epoch 70 cost J = 0.0939087\n",
      "Reached epoch 80 cost J = 0.091067\n",
      "Reached epoch 90 cost J = 0.0886948\n",
      "Reached epoch 100 cost J = 0.0866975\n",
      "0.824533\n",
      "0.8244\n"
     ]
    }
   ],
   "source": [
    "acc_train, acc_test, sess, cost_history = model_layers(minibatch_size = 41, \n",
    "                              training_epochs = 100, \n",
    "                              features = train, \n",
    "                              classes = labels_, \n",
    "                              logging_step = 10,\n",
    "                              learning_r = 1e-6,\n",
    "                              number_neurons = 100, debug = True)\n",
    "print(acc_train)\n",
    "print(acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_ = np.random.randint(low=35, high=60.0, size=(20))\n",
    "\n",
    "#r = - np.arange(0,1,0.05)*4.0\n",
    "r = -np.random.random([20])*(6-5)-5\n",
    "\n",
    "learning_ = 10**r\n",
    "\n",
    "mb_size_ = np.random.randint(low=20, high=80, size = 20)\n",
    "\n",
    "epochs_ = np.random.randint(low = 40, high = 100, size = (20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 65 Number: 46 learning 3.75743361986e-06 mb size 20 Acc. Train: 0.838683 Acc. Test 0.8407\n",
      "epochs: 54 Number: 37 learning 7.12390609733e-06 mb size 56 Acc. Train: 0.8246 Acc. Test 0.8241\n",
      "epochs: 42 Number: 37 learning 2.14766290607e-06 mb size 45 Acc. Train: 0.712933 Acc. Test 0.7131\n",
      "epochs: 70 Number: 39 learning 5.59340704666e-06 mb size 76 Acc. Train: 0.814483 Acc. Test 0.8107\n",
      "epochs: 83 Number: 50 learning 8.14470677233e-06 mb size 32 Acc. Train: 0.1 Acc. Test 0.1\n",
      "epochs: 60 Number: 44 learning 3.97668096387e-06 mb size 58 Acc. Train: 0.8123 Acc. Test 0.815\n",
      "epochs: 52 Number: 35 learning 2.11130468914e-06 mb size 78 Acc. Train: 0.691283 Acc. Test 0.6906\n",
      "epochs: 70 Number: 43 learning 4.94147290757e-06 mb size 32 Acc. Train: 0.837283 Acc. Test 0.8374\n",
      "epochs: 70 Number: 44 learning 8.09986058619e-06 mb size 59 Acc. Train: 0.847767 Acc. Test 0.8477\n",
      "epochs: 46 Number: 35 learning 3.28760183015e-06 mb size 37 Acc. Train: 0.779567 Acc. Test 0.777\n",
      "epochs: 51 Number: 46 learning 3.11646009783e-06 mb size 41 Acc. Train: 0.805367 Acc. Test 0.8057\n",
      "epochs: 96 Number: 58 learning 2.05750793342e-06 mb size 49 Acc. Train: 0.820183 Acc. Test 0.8206\n",
      "epochs: 61 Number: 54 learning 1.30537893914e-06 mb size 38 Acc. Train: 0.77015 Acc. Test 0.768\n",
      "epochs: 72 Number: 45 learning 2.88601092474e-06 mb size 52 Acc. Train: 0.8057 Acc. Test 0.8053\n",
      "epochs: 94 Number: 52 learning 5.31016599e-06 mb size 37 Acc. Train: 0.1 Acc. Test 0.1\n",
      "epochs: 84 Number: 54 learning 2.97351049253e-06 mb size 43 Acc. Train: 0.832483 Acc. Test 0.831\n",
      "epochs: 42 Number: 36 learning 8.22904299748e-06 mb size 25 Acc. Train: 0.836567 Acc. Test 0.8364\n",
      "epochs: 70 Number: 50 learning 2.24455609222e-06 mb size 34 Acc. Train: 0.81065 Acc. Test 0.8111\n",
      "epochs: 93 Number: 37 learning 2.90045439769e-06 mb size 28 Acc. Train: 0.82645 Acc. Test 0.8278\n",
      "epochs: 82 Number: 36 learning 6.71104798403e-06 mb size 72 Acc. Train: 0.8331 Acc. Test 0.8329\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(neurons_)):\n",
    "    #print('Number:',neurons_[i],'learning', learning_[i])\n",
    "    acc_train, acc_test, sess, cost_history = model_layers(minibatch_size = mb_size_[i], \n",
    "                              training_epochs = epochs_[i], \n",
    "                              features = train, \n",
    "                              classes = labels_, \n",
    "                              logging_step = 10,\n",
    "                              learning_r = learning_[i],\n",
    "                              number_neurons = neurons_[i], debug = False)\n",
    "    print('epochs:', epochs_[i], 'Number:',neurons_[i],'learning', learning_[i], 'mb size',mb_size_[i],\n",
    "          'Acc. Train:', acc_train, 'Acc. Test', acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
